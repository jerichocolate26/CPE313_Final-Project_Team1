# Assessing Dogs Activity using Deep Learning

## Abstract:
This research presents a novel framework for recognizing dog activities from video sequences using deep learning. The framework employs YOLO object detection to accurately localize dogs within video frames, followed by Recurrent Neural Networks (RNNs) for temporal activity modeling. Specifically, Vanilla LSTM, Bidirectional LSTM, and Stacked LSTM architectures are investigated to capture different patterns in dog movements and classify activities like running, walking, playing, and resting.

Experiments on a diverse dataset of dog activity videos demonstrate the superior performance of the proposed YOLO-RNN framework compared to traditional methods. A comparative analysis of the RNN architectures reveals their relative strengths in capturing various activity patterns.

This research contributes to the advancement of automated dog behavior analysis, with potential applications in animal welfare, veterinary care, and human-animal interaction studies. The proposed framework, by accurately recognizing dog activities, can enhance our understanding of canine behavior and ultimately improve the lives of dogs and their human companions.

## Authors:
- Ecubin, Jericho Paul C.
- Estacion, Kenneth

## Links for Documents and Datasets

- Full Paper (IMRAD format): https://docs.google.com/document/d/1iBOdQN3GjonfwcXYmDoqewk6ZcYUuOsNeLIuZ4gQloc/edit?usp=sharing
- Datasets & Models: https://drive.google.com/drive/folders/1V-bgd0-9fHhQUFlRIvRIe7YfS0LOyLBf?usp=drive_link
- Roboflow Dataset: https://universe.roboflow.com/project-sa4qf/dogs_detection_0728
- Video demonstration: https://drive.google.com/file/d/129nTCnH5GDxghLkPhKB145yRbg-moS7Z/view?usp=sharing
